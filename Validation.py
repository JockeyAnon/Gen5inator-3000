import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
import matplotlib.ticker as mticker
from matplotlib import cm
from tsmoothie.smoother import *
import math
from scipy import signal
import matplotlib.gridspec as gridspec
import glob
from matplotlib.ticker import ScalarFormatter
import os
from matplotlib.pyplot import cm
from ast import literal_eval

import datetime

from scipy.spatial import Delaunay 
import struct
from stl import mesh
import matplotlib.tri as mtri
import time
def local_write_facet(f, p1, p2, p3, mode):
    if np.isnan(p1).any() or np.isnan(p2).any() or np.isnan(p3).any():
            return 0

    n = local_find_normal(p1, p2, p3)
    if mode == 'ascii':
        f.write('facet normal %.7f %.7f %.7f\n' % (n[0], n[1], n[2]))
        f.write('outer loop\n')
        f.write('vertex %.7f %.7f %.7f\n' % (p1[0], p1[1], p1[2]))
        f.write('vertex %.7f %.7f %.7f\n' % (p2[0], p2[1], p2[2]))
        f.write('vertex %.7f %.7f %.7f\n' % (p3[0], p3[1], p3[2]))
        f.write('endloop\n')
        f.write('endfacet\n')
    else:
        f.write(struct.pack('%sf' % len(n), *n))
        f.write(struct.pack('%sf' % len(p1), *p1))
        f.write(struct.pack('%sf' % len(p2), *p2))
        f.write(struct.pack('%sf' % len(p3), *p3))
        f.write(struct.pack('h', 0))
    return 1

def local_find_normal(p1, p2, p3):
    v1 = p2 - p1
    v2 = p3 - p1
    v3 = np.cross(v1, v2)
    n = v3 / math.sqrt(np.sum(v3*v3))
    return n

def write(filename, x, y, z, mode='binary'):
    """
    Write a stl file for a surface with geometry
    defined from three matrix arguments, x, y, and z.
    Meshes are triangulated sequencially along xyz order.

    Parameters
    ----------
    filename : string
        output file name

    x, y, z : ndarray
        Arguments x, y can be 1-dimensional arrays or 2-dimensional grids
        (usually generated by np.meshgrid(x,y)), and z must be 2-dimensional,
        which must have len(x)=n, len(y)=m where z.shape[m,n].

    mode : string
        STL file format, 'ascii' or 'binary'(default).

    Examples
    ----------
    import numpy as np
    import surf2stl

    x = np.linspace(-6, 6, 30)
    y = np.linspace(-6, 6, 30)
    X, Y = np.meshgrid(x, y)
    Z = np.sin(np.sqrt(X ** 2 + Y ** 2))

    surf2stl.write('3d-sinusoidal.stl', X, Y, Z)

    """

    if type(filename) is not str:
        raise Exception('Invalid filename')

    if mode != 'ascii':
        mode = 'binary'

    if z.ndim != 2:
        raise Exception('Variable z must be a 2-dimensional array')

    ### x, y can not be used as dx, dy in Python
    ### if arguments type of x(or y) is 'int',
    ### type error will raise in next 'if' block
    # if type(x) == int and type(y) == int:
    #    x = np.arange(0, z.shape[1], x)
    #    x = np.arange(0, z.shape[0], y)

    if len(x.shape) == 1 and x.shape[0] == z.shape[1] \
            and len(y.shape) == 1 and y.shape[0] == z.shape[0]:
        x, y = np.meshgrid(x, y)

    if len(x.shape) != len(z.shape) \
            or len(y.shape) != len(z.shape) \
            or x.shape[1] != z.shape[1] \
            or y.shape[0] != z.shape[0]:
        raise Exception('Unable to resolve x and y variables')

    nfacets = 0
    title_str = 'Created by surf2stl.py %s' % datetime.datetime.now().strftime('%d-%b-%Y %H:%M:%S')

    f = open(filename, 'wb' if mode != 'ascii' else 'w')

    if mode == 'ascii':
        f.write('solid %s\n' % title_str)
    else:
        title_str_ljust = title_str.ljust(80)
        # f.write(title_str_ljust.encode('utf-8')) # same as 'ascii' for alphabet characters
        f.write(title_str_ljust.encode('ascii'))
        f.write(struct.pack('i', 0))

    for i in range(z.shape[0]-1):
        for j in range(z.shape[1]-1):
            p1 = np.array([x[i,j], y[i,j], z[i,j]])
            p2 = np.array([x[i,j+1], y[i,j+1], z[i,j+1]])
            p3 = np.array([x[i+1,j+1], y[i+1,j+1], z[i+1,j+1]])
            val = local_write_facet(f, p1, p2, p3, mode)
            nfacets += val

            p1 = np.array([x[i+1,j+1], y[i+1,j+1], z[i+1,j+1]])
            p2 = np.array([x[i+1,j], y[i+1,j], z[i+1,j]])
            p3 = np.array([x[i,j], y[i,j], z[i,j]])
            val = local_write_facet(f, p1, p2, p3, mode)
            nfacets += val

    if mode == 'ascii':
        f.write('endsolid %s\n' % title_str)
    else:
        f.seek(80, 0)
        f.write(struct.pack('i', nfacets))

    f.close()

    print('Wrote %d facets' % nfacets)
    return

startTOTAL_time = time.time()
#Initial Declaration for the processed data cache. Each corresponds to a concentration, while the last one corresponds to the control. There are 12 arrays nested within each array for each graph type.
#The reason why the data is stored in cache type instead of processed on-demand is because the final data graphs use the same data but in different visualizations.

totaldataarray = [[],[],[],[],[],[],[],[],[],[],[],[]]
od600dataarray = [[],[],[],[],[],[],[],[],[],[],[],[]]
rawnorm1array = [[],[],[],[],[],[],[],[],[],[],[],[]]
rawnorm2array = [[],[],[],[],[],[],[],[],[],[],[],[]]
raw11 = [[],[],[],[],[],[],[],[],[],[],[],[]]
rawcntrlf = [[],[],[],[],[],[],[],[],[],[],[],[]]
rawcntrlod = [[],[],[],[],[],[],[],[],[],[],[],[]]
rawcntrl = [[],[],[],[],[],[],[],[],[],[],[],[]]


#This is a customized profile based on the type of protocols done by the plate reader. This is subject to change based on the type of experiments done.
#Number of protocols done(INCLUDING OD600/absorbance readings)
readProtocols = 2
#Number of time points/individual read steps done(IMPORTANT TO GET EXACT)
numberOfReads = 217
#Number of columns on the plate
columnsum = 12
#Number of rows in the plate
rowsum = 8
#Protocol-specific: The titration factor
titrationBase = 2
#Graph-specific: The timeframe within the total number of reads the graphs should visualize
timeframe = 217
#Graph-specific: When you want to start the graphing window from the previous variable to start
timestart = 0
#Graph-specific: Which row you want to start from
figurerownumber = 0
#Graph-specific: Which column you want to start from
figurecolnumber = 0

#The list of strain names in array form. The first is formatted so sequential graph generation can take the label of the graph from this array in the same format as the graphs are referenced in subplot array format.
strainlist = [["atpB", "petA", "sucC", "rpoA", "fabA"],["A.S. 28 factor", "unchar. protein I", "cspA2", "P. ABC Trans. System", "gitA"],["lpxC", "unchar. protein II", "capB", "P. O.M. porin A", "acrA"]]
#This list of strain names comes in list format so the referencing of graphs is completely sequential in the case of alternative subplot referencing(This is the method used right now.)
strainlist2 = ["atpB", "petA", "sucC", "rpoA", "fabA","A.S. 28 factor", "unchar. protein I", "cspA2", "P. ABC Trans. System", "gitA","lpxC", "unchar. protein II", "capB", "P. O.M. porin A", "acrA"]

#Stores dataframes generated directly from pandas
#   Dataframe array format = [File index(0 = first excel sheet read)][horizontal index(all columns for each row listed in alphabetical and numerical order)][vertical index(time point)]
dataframes = []

#Changes current working directory to the file with the spreadsheet data (REMEMBER TO SET THE PLATE NAMES TO ALPHABETICAL ORDER)
val = input("Enter data folder name (CASE SENSITIVE): ")
newdir = "C:/Users/Daniel Park/Desktop/"+val+"/"
os.chdir(newdir)
path = os.getcwd() 
f = os.listdir(path)


#Checks for a "processeddata.csv" file that would have formed if the data was previously calculated. This makes it so that the program does not have to run the calculations again just to graph
if os.path.exists(newdir+"processeddata.csv"):
    print("Previous Calculated Data Detected!")
    start_time = time.time()
    #Imports the csv as a data array
    toimport = pd.read_csv("processeddata.csv")
    #Turns the data array into a numpy array, then transposed to align the data to the right lists
    combinedarray = toimport.to_numpy().transpose()
    #Distributes precalculated data into the right variables
    totaldataarray = [literal_eval(i) for i in combinedarray[1]]
    od600dataarray = [literal_eval(i) for i in combinedarray[2]]
    rawnorm1array = [literal_eval(i) for i in combinedarray[3]]
    rawnorm2array = [literal_eval(i) for i in combinedarray[4]]
    raw11 = [literal_eval(i) for i in combinedarray[5]]
    rawcntrlf = [literal_eval(i) for i in combinedarray[6]]
    rawcntrlod = [literal_eval(i) for i in combinedarray[7]]
    rawcntrl = [literal_eval(i) for i in combinedarray[8]]
    print("--- Time elapsed to load data: %s seconds ---" % (time.time() - start_time))
    print("Data Loaded!")
else:
    print("No Previous Calculated Data Detected!")
    start_time = time.time()
    csv_files = glob.glob(os.path.join(path, "*.xlsx")) 

    #Turns all the xlsx spreadsheets into dataframes and transposed to make index calls easier
    for f in csv_files:
        dataframes.append(pd.read_excel(f).values.transpose())
    #Reads the dataframe to know where the OD600 starts
    od600StartIndex = np.where(dataframes[0][0]=="OD:600")[0][0] + 3

    #fold change values are calculated as follows (data/od600)/(control data/control od600)
    def foldchangeval(i,k,l,m,n):
        #ex1. dataframes[i][3+12*k+l][n+m] = referencing on sheet i the value in the cell 4(3+1) + l(the concentration in particular) + 12*k(row number) columns from the left and n+m(dataframe start value + read number)
        #ex2. dataframes[i][3+12*k+11][n+m] = referencing on sheet i the value in the cell 4(3+1) + 11(drags it to the final column value(control)) + 12*k(row number) columns from the left and n+m(dataframe start value + read number) 
        return ((dataframes[i][3+l+12*k][n+m]/dataframes[i][3+l+12*k][od600StartIndex+m])/(dataframes[i][3+11+(12*k)][n+m]/dataframes[i][3+11+(12*k)][od600StartIndex+m]))
    #Raw Fluorescense data from non control normalized by the corresponding instance's od600
    def rawnorm1(i,k,l,m,n):
        return ((dataframes[i][3+l+(12*k)][n+m]/dataframes[i][3+12*k+l][od600StartIndex+m]))
    #Raw Fluorescense data from control normalized by the corresponding instance's od600
    def rawnorm2(i,k,l,m,n):
        return ((dataframes[i][3+l+(12*k)][n+m]/dataframes[i][3+11+(12*k)][od600StartIndex+m]))


    #This is for the fold change magnitudes

    #Goes through the dataframes
    for i in range(len(dataframes)):

        for j in range(readProtocols-1):
            n = (od600StartIndex)+(numberOfReads+4)*(j+1)
            for k in range(rowsum):
                for l in range(columnsum):
                    y = []
                    od = []
                    raw1 = []
                    raw2 = []
                    raw = []
                    rawf = []
                    rawod=[]
                    rawcomb=[]
                    for m in range(numberOfReads):
                        if m < timestart:
                            continue
                        if m == timeframe:
                            break
                        y.append(foldchangeval(i,k,l,m,n))
                        od.append(dataframes[i][3+12*k+l][od600StartIndex+m])
                        raw1.append(rawnorm1(i,k,l,m,n))
                        raw2.append(rawnorm2(i,k,l,m,n))
                        raw.append(dataframes[i][3+11+(12*k)][n+m]/dataframes[i][3+11+(12*k)][od600StartIndex+m])
                        rawf.append(dataframes[i][3+12*k+l][n+m])
                        rawod.append(dataframes[i][3+12*k+l][od600StartIndex+m])
                        rawcomb.append(dataframes[i][3+12*k+l][n+m]/dataframes[i][3+12*k+l][od600StartIndex+m])
                    totaldataarray[l].append(y)
                    od600dataarray[l].append(od)
                    rawnorm1array[l].append(raw1)
                    rawnorm2array[l].append(raw2)
                    raw11[l].append(raw)
                    rawcntrlf[l].append(rawf)
                    rawcntrlod[l].append(rawod)
                    rawcntrl[l].append(rawcomb)
    dict = {'total': totaldataarray, 'od600': od600dataarray, 'raw1': rawnorm1array, 'raw2': rawnorm2array, 'raw': raw11, 'rawf': rawcntrlf, 'rawod': rawcntrlod, 'rawcomb': rawcntrl}
    df = pd.DataFrame(dict)
    df.to_csv('processeddata.csv')
    print("--- Time elapsed to calculate data: %s seconds ---" % (time.time() - start_time))
    print('Data file generated!')

newpath1 = newdir + "Graphics/"     
if not os.path.exists(newpath1):
    os.makedirs(newpath1)

# print("Generating Graph Set 1...")
# start_time = time.time()
# for i in range(12):
#     for j in range(8):
#         tempfig = plt.figure()
#         hold = tempfig.add_subplot()
#         hold.plot(np.linspace(0,217,217), totaldataarray[i][0+j], '.', markersize = 3,color = 'blue')
#         newpath = newpath1 + "First Runs/Fixed Concentration, Time/Singles/" 
#         if not os.path.exists(newpath):
#             os.makedirs(newpath)
#         filename = newpath + 'first runs concentration 0.5^' + str(i) + ' strain ' + str(j+1) + '.png'
#         tempfig.savefig(filename)
#         plt.close(tempfig)
# print("--- Time elapsed to generate this graph set: %s seconds ---" % (time.time() - start_time))
# print("Graphs Generated and Stored!")

# # This is for averaged with error bands with concentrations overlapped
# print("Generating Graph Set 10...")
# start_time = time.time()
# tempfig = plt.figure(figsize=(16, 10.0),layout = 'constrained')
# tempfig.set_constrained_layout_pads(w_pad=0.3, h_pad=0.2,hspace=0, wspace=0)
# color = cm.rainbow(np.linspace(0, 1, 12))

# for j in range(8):
#     hold = tempfig.add_subplot(3,5,j+1)
#     hold.set_title(strainlist2[j], fontweight = 'bold',fontsize=20)
#     for i, c in enumerate(color):

#         means = totaldataarray[i][0+j]

#         if i == 11:
#             hold.plot(np.linspace(0,217,217), means, '-', c=c, label='C = 0 uM', linewidth=2)

#         else:
#             hold.plot(np.linspace(0,217,217), means, '-', markersize = 10, c=c, label='C = ' + str(round(10*(0.5**i),3)) + ' uM', linewidth=5.0)

#         hold.set_ylim([0.7, 1.2])
#         hold.set_xticks(np.linspace(0, 217, 217),fontweight='bold')
#         hold.set_yticks(np.linspace(0.7, 1.2, 5),fontweight='bold')
#         hold.set_xticklabels([int(number) for number in (np.linspace(0,18,217))],fontweight='bold')
#         hold.set_yticklabels(np.around(np.arange(0.7, 1.2, 0.1),2),fontweight='bold')
#         hold.tick_params(axis='both', labelsize=20)
#         hold.locator_params(nbins = 3, axis='both')
#         hold.spines[['right', 'top']].set_visible(False)
# newpath = newpath1 + "Averaged with errors/Fixed Concentration, Time/" 
# if not os.path.exists(newpath):
#     os.makedirs(newpath)           
# filename = newpath + 'overlapped concentration 0.5^' + str(i) + ' strain ' + str(j+1) + '.png'
# tempfig.savefig(filename)
# plt.close(tempfig)
# print("--- Time elapsed to generate this graph set: %s seconds ---" % (time.time() - start_time))
# print("Graphs Generated and Stored!")

# #This is for overlapped OD600, same style as the previous overlapped graph
# print("Generating Graph Set 13...")
# start_time = time.time()
# fig, ax = plt.subplots(3,5,figsize=(24, 12))
# fig.subplots_adjust(wspace = 0.5,hspace = 1)
# color = cm.rainbow(np.linspace(0, 1, 12))
# lines = []
# a = 0
# b = 0
# for j in range(8):
    
    
#     ax[a,b].set_title(strainlist2[j], fontsize=35,pad=35)
    
#     for i, c in enumerate(color):

#         means = od600dataarray[i][0+j]

#         if i == 11:
#             ax[a,b].plot(np.linspace(0,217,217), means, '.', markersize = 10, c=c, label='C = 0 uM')
#         else:
#             ax[a,b].plot(np.linspace(0,217,217), means, '.', markersize = 10, c=c, label='C = ' + str(round(10*(0.5**i),3)) + ' uM')
#         lines.append(ax[a,b].plot(np.linspace(0,217,217), means, '-', markersize = 6, c=c))

#         ax[a,b].set_ylim([0, 1.5])
#         ax[a,b].locator_params(axis='y', nbins=2.5) 
#         ax[a,b].spines[['right', 'top']].set_visible(False)
#         ax[a,b].tick_params(axis='both', labelsize=35)
        
#     b = b+1
#     if b == 5:
#         b = 0
#         a = a+1
# newpath = newpath1 + "OD600/Overlapped/" 
# if not os.path.exists(newpath):
#     os.makedirs(newpath)   
# filename = newpath + 'overlapped concentration 0.5^' + str(i) + ' strain ' + str(j+1) + '.png'
# ax[2,4].legend(bbox_to_anchor=(1.75, 3.75))

# fig.savefig(filename)
# plt.close(fig)
# print("--- Time elapsed to generate this graph set: %s seconds ---" % (time.time() - start_time))
# print("Graphs Generated and Stored!")

# #This is for overlapped Raw1, same style as the previous overlapped graph
# print("Generating Graph Set 14...")
# start_time = time.time()
# fig, ax = plt.subplots(3,5,figsize=(24, 12))
# fig.subplots_adjust(wspace = 0.5,hspace = 1)
# color = cm.rainbow(np.linspace(0, 1, 12))
# lines = []
# a = 0
# b = 0
# for j in range(8):
    
    
#     ax[a,b].set_title(strainlist2[j], fontsize=35,pad=35)
    
#     for i, c in enumerate(color):

#         means = rawnorm2array[i][0+j]

#         if i == 11:
#             ax[a,b].plot(np.linspace(0,217,217), means, '.', markersize = 1, c=c, label='C = 0 uM')
#         else:
#             ax[a,b].plot(np.linspace(0,217,217), means, '.', markersize = 1, c=c, label='C = ' + str(round(10*(0.5**i),3)) + ' uM')
#         lines.append(ax[a,b].plot(np.linspace(0,217,217), means, '-', markersize = 1, c=c))
#         # ax[a,b].set_ylim([0, 1.5])
#         ax[a,b].locator_params(axis='y', nbins=2.5) 
#         ax[a,b].spines[['right', 'top']].set_visible(False)
#         ax[a,b].tick_params(axis='both', labelsize=35)
        
#     b = b+1
#     if b == 5:
#         b = 0
#         a = a+1
# newpath = newpath1 + "Raw2/Overlapped/" 
# if not os.path.exists(newpath):
#     os.makedirs(newpath)   
# filename = newpath + 'overlapped concentration 0.5^' + str(i) + ' strain ' + str(j+1) + '.png'
# ax[2,4].legend(bbox_to_anchor=(1.75, 3.75))

# fig.savefig(filename)
# plt.close(fig)
# print("--- Time elapsed to generate this graph set: %s seconds ---" % (time.time() - start_time))
# print("Graphs Generated and Stored!")

# #3D graph portion:

# x = np.arange(0,numberOfReads).transpose()
# for i in range(readProtocols-1):

#     for j in range(rowsum):
#         plt.figure((i+1)*j)
#         ax = plt.axes(projection='3d')
#         xlist = []
#         ylist = []
#         zlist = []
#         for k in range(columnsum):
#             y = []
#             for l in range(numberOfReads):
#                 if l < timestart:
#                     continue
#                 if l == timeframe:
#                     break
#             xlist.append(np.linspace(timestart,timeframe,timeframe-timestart))
#             ylist.append(np.full((timeframe-timestart, ), k))
#             smoother = ConvolutionSmoother(window_len=80, window_type='ones')
#             smoother.smooth(totaldataarray[k][j])
#             zlist.append(smoother.smooth_data[0])
#         ax.set_title("3D Representation of Inducer Reaction across a Base-2 Concentration Gradient")
#         ax.plot_surface(np.array(xlist), np.array(ylist), np.array(zlist),cmap=cm.coolwarm,antialiased=True)
#         ax.set_xlim3d(0, timeframe-timestart)
#         ax.set_ylim3d(0, columnsum-1)
#         ax.set_xlabel('Time (5 min/incr)')
#         ax.set_ylabel('Well Number(Concentration = 0.5 ^ Well Number)')
#         ax.set_zlabel('Fluorescence Intensity') 
#     plt.show()

#3D graph portion:

x = np.arange(0,numberOfReads).transpose()
for i in range(readProtocols-1):

    for j in range(rowsum):
        plt.figure((i+1)*j)
        ax = plt.axes(projection='3d')
        xlist = []
        ylist = []
        zlist = []
        for k in range(columnsum-1):
            y = []
            for l in range(numberOfReads):
                if l < timestart:
                    continue
                if l == timeframe:
                    break
            xlist.append(np.linspace(timestart,timeframe,timeframe-timestart))
            ylist.append(np.full((timeframe-timestart, ), k))
            smoother = ConvolutionSmoother(window_len=80, window_type='ones')
            smoother.smooth(totaldataarray[k][j])
            zlist.append(smoother.smooth_data[0])

        ax.plot_surface(np.array(xlist), np.array(ylist), np.array(zlist),cmap=cm.coolwarm,antialiased=True)
        ax.set_xlim3d(0, timeframe-timestart)
        ax.set_ylim3d(0, columnsum-1)
        ax.grid(False)
        ax.axis(False)
        write('C:/Users/Daniel Park/Desktop/Experiment3/Graphics/STL/strain' + str(j) + '.stl', np.array(xlist), np.array(ylist), np.array(zlist))
    plt.show()
    
